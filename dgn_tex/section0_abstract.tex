\begin{abstract}
Generative adversarial networks (GANs) can be trained to model complex image distributions where it is inconvenient or intractable to assign a probabilistic structure to the likelihood function. Earlier models achieved realistic samples, but suffered from mode collapse --- when samples do not cover the full domain of the distribution. More recent models have resolved issues of mode collapse by using alternative \textit{adversaries} in their objective functions, which ensure that each mode in the data distribution is covered by the generated samples. With proper coverage, however, a new challenge emerges: Given that data is biased in a known way, adjust the model to compensate for this bias. Here, we introduce a simple structure within a maximum mean discrepancy (MMD) objective function, which provides a flexible way of re-balancing generated data and directing the generative function toward a target group. The weighted MMD interprets the bias as a thinning function on the empirical data measure, and yields a manipulable discrepancy measure that can sway generative samples toward a chosen set of labeled points. \end{abstract}